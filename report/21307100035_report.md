## 预处理使用tag聚类
数据选择：计算不同平台的基尼系数和信息熵，发现 stackoverflow 的数据最好

1. 分词(使用jieba) 停用词处理(使用baidu_stopwords)
2. 出现的tag太少,或者所有的tag出现次数都太少,属于不适合聚类的数据,删除tag,如果一个数据没有tag,删除这条数据
3.  聚类1: 使用louvain进行聚类，然后根据louvain聚类的数量，因为louvain预测新的值需要建立新的图，而kmeans不需要，所以最后还需要是k-means的形式
4. 聚类2:使用k-means进行聚类,过滤使用频率在千分之4之下的tag,使用肘部法,确定最佳的聚类的k值为3400左右,确定最佳k值的时按照tag出现的次数权重提取10000个样本,同时对tag的one-hot编码使用pca进行降维 
5. ![elbow_plot_pca](./21307100035_report.assets/elbow_plot_pca.png)
根据肘部图选择合适的 k 值大约为 3400


## 使用body和title进行预测tag
1. 最开始使用预训练的词嵌入技术,存在这样的问题:大量的专业名词没有对应的预训练模型,使用bert中文和英文共存的预训练模型维度过大,训练后有180个g,无法进行处理
2. 最后选择使用tfidf进行预测tag,使用MultiLabelBinarizer对标签进行one-hot编码,使用MultiOutputClassifier进行多标签分类训练(在predict_tag)
特征数量: 230171 预测特征数量 107 相当于 107个LogisticRegression线性回归模型

## 对小红书爬虫数据进行处理，预测 tag 后进行统计：
excel 很少，推测是关键词的问题，但是为了获得更好的数据，关键词必须有代码，程序代写，excel 可能是数据处理一类的，这里面的权重不好把握
