## 预处理使用tag聚类

1. 分词(使用jieba) 停用词处理(使用baidu_stopwords)
2. 出现的tag太少,或者所有的tag出现次数都太少,属于不适合聚类的数据,删除tag,如果一个数据没有tag,删除这条数据
3. 
    聚类1: 使用louvain进行聚类，然后根据louvain聚类的数量，因为louvain预测新的值需要建立新的图，而kmeans不需要，所以最后还需要是k-means的形式
4. 聚类2:使用k-means进行聚类,过滤使用频率在千分之4之下的tag,使用肘部法,确定最佳的聚类的k值为3400左右,确定最佳k值的时按照tag出现的次数权重提取10000个样本,同时对tag的one-hot编码使用pca进行降维 
5. ![elbow_plot_pca](./21307100035_report.assets/elbow_plot_pca.png)

## 使用body和title进行预测tag

1. 最开始使用预训练的词嵌入技术,存在这样的问题:大量的专业名词没有对应的预训练模型,使用bert中文和英文共存的预训练模型维度过大,训练后有180个g,无法进行处理
2. 最后选择使用tfidf进行预测tag,使用MultiLabelBinarizer对标签进行one-hot编码,使用MultiOutputClassifier进行多标签分类训练(在predict_tag)



## 可以做的

data里面有word_count_output.txt,里面有频率,可以做词云